# 클러스터의 확장성

- `확장성` : 운영 중인 시스템에서 증가하는 트래픽에 유연하게 대응할 수 있는 능력

## 스케일 업 vs 스케일 아웃

- `스케일 업`: 서버의 하드웨어를 높은 사양으로 업그레이드 하는 것 (= 수직 확장)
    - 비교적 간단하고 비용도 적게 듦
    - 하드웨어 허용 범위 내에서만 확장이 가능하여 한계가 존재
- `스케일 아웃` : 장비를 추가해 시스템을 확장시키는 방식 (= 수평 확장)
    - 장비를 추가하는 만큼 성능 확장 가능
    - 데이터가 여러 대의 서버에 분산 처리돼야 하므로 분산 처리에 대한 로직 추가 개발 필요

## 레디스에서의 확장성

### 스케일 업

- 키 만료가 자주 일어나는 경우 (`maxmemory`만큼 데이터가 차 있을 때 데이터를 저장할 때 발생)
- 서버 메모리 업그레이드 후 `maxmemory` 값 증가 가능

### 스케일 아웃

- 레디스는 단일 스레드로 동작하므로 여러 서버로 분할해 관리하면 병렬로 요청 처리 가능

## 클러스터의 기능

- 애플리케이션 아키텍처 변경 없이 여러 레디스 인스턴스 간 수평 확장 가능
- 데이터의 분산 처리, 복제, 자동 페일오버 기능 사용 가능

### 1) 데이터 샤딩

- 데이터 저장소를 수평 확장하며 여러 서버 간에 데이터를 분할하는 DB 아키텍처 패턴
- 최대 1,000개의 마스터 사용 가능
- 샤딩 관련 기능은 내부에서 자체적으로 관리되어 프록시 서버 등의 추가 아키텍처는 불필요
- **키를 이용해 샤딩, 하나의 키는 항상 하나의 마스터 노드에 매핑**
- 클러스터의 모든 노드는 키가 저장되어야 할 노드를 알고 있으며,
    
    클라이언트가 다른 노드에 데이터를 쓰거나 읽으려 할 때 키가 할당된 마스터 노드로 연결
    
    - 레디스 노드와 애플리케이션 내 레디스 클라이언트에서 처리되어 애플리케이션 내 분할 저장 관련 로직 구현 불필요
- 클러스터 내에서 특정 키가 어떤 마스터에 저장되어 있는지 캐싱하여 조회 시간 단축

### 2) 고가용성

- 마스터, 복제본 각각 최소 3대로 구성하는 것이 일반적
- 클러스터 구성에 속한 각 노드는 서로를 모니터링
- 마스터 노드 장애 발생 시 이를 인지한 다른 노드들이 마스터에 연결된 복제본 노드를 마스터로 자동 페일 오버시킴
    
    ⇒ 가용성 증가
    
- 마스터에 연결된 복제본의 개수를 파악해 잉여 복제본을 필요한 노드에 연결시키는 복제본 마이그레이션 작업도 수행

**클러스터 버스**

- 클러스터 내 노드들의 독립적인 통신
- 모든 레디스 클러스터 노드는 다른 레디스 클러스터 노드에서 들어오는 연결을 수신하기 위해 추가 TCP 포트가 열려 있음
    - 클라이언트로부터 커맨드를 받는 TCP 포트와 독립적으로 동작
- `cluster_bus_port` 값을 정의하지 않으면 일반 포트에 `10000`을 도한 값으로 자동 설정

**토폴로지**

- **모든 노드가 다른 모든 노드와 연결되어 있는 Full-Mesh 토폴로지 형태**
- 노드 간 메시지 교환으로 인한 오버헤드는 걱정하지 않아도 됨
- 가십 프로토콜과 구성 업데이트 메커니즘을 이용해 정상 상태에서는 많은 메시지 교환 X
- 노드가 증가하더라도 메시지가 급증하지 않도록 설계됨

# 레디스 클러스터 동작 방법

## 해시슬롯을 이용한 데이터 샤딩

- 모든 데이터는 해시슬롯에 저장
- 16,834개의 해시슬롯을 가지며, 마스터 노드 개수에 따라 나눠서 각각 나눠서 사용
- 데이터 저장/조회 시 해시 함수 사용하여 마스터 노드를 찾아감
    
    ```bash
    # 해시 함수
    HASH_SLOT = CRC16(key) mod 16834 # CRC16으로 암호화 후 나머지 계산
    ```
    
- 마스터 노드 내에서 자유롭게 옮길 수 있고 옮겨지는 중에도 데이터 정상 접근 가능,
    
    이로 인해 클러스터 내 마스터 노드의 추가/삭제는 자유로움
    

## 해시태그

- 클러스터는 키를 이용해 커맨드를 처리할 마스터로 클라이언트의 연결을 리디렉션하기 때문에
    
    한 번에 2개 이상의 각각 다른 마스터에 연결된 해시슬롯에 접근해야 하는 커맨드는 사용 불가
    
- 하지만 키에 중괄호를 사용하면 전체 키가 아닌 중괄호 내 값을 이용해 해싱 가능
    
    ```bash
    user:{123}:profile
    user:{123}:account
    ```
    
    - 중괄호 내 문자열이 존재하지 않을 경우 전체 키로 해싱
    - 중괄호가 여러 쌍이 존재하는 경우 첫 번째 중괄호 내 값으로 해싱
- 단, 너무 많은 키가 같은 해시태그를 갖고 있을 경우 하나의 해시슬롯에 데이터가 몰려 키 분배에 대한 모니터링 필요

## 자동 재구성

- 센티널과 달리 데이터를 저장하는 레디스 노드가 서로 감시
- 인스턴스에 문제가 생겼을 때 자동으로 클러스터 구조 갱신
- 가용성이 중요할 때 클러스터 노드의 다운타임을 줄이기 위해서는 자동 복제본 마이그레이션이 가능하도록 아무 마스터 노드에 복제본을 하나 더 추가하는 것을 고려

### 1) 자동 페일오버

- 마스터 노드 장애 발생 시 다른 마스터 노드들에게 페일오버 시도 관련 투표 요청
- 투표 요청을 받은 노드가 현재 장애 발생 노드가 정상이 아니라고 판단할 경우 복제본에게 투표
- 과반수 이상의 마스터 노드에서 투표를 받은 복제본은 마스터로 승격
- 이후 새로운 마스터도 장애 발생 시 `cluster-require-full-coverage` 옵션이 `yes`인 경우 전체 클러스터 사용 불가
    - 해당 옵션의 기본 값은 `yes`
    - 레디스 클러스터에서 일부 노드만 다운되어도 데이터 정합성을 위해 클러스터 전체 FAIL
        
        (문제가 생긴 해시슬롯을 포함한 전체 해시슬롯에 대한 데이터의 조작도 실패)
        

### 2) 자동 복제본 마이그레이션

- 잉여 복제본 노드를 다른 마스터에 연결하여 클러스터 가용성을 높이는 방식
- `cluster-allow-replica-migration` 옵션이 `yes`인 경우에만 동작 (기본 값 : `yes`)
- `cluster-migration-barrier` 옵션은 복제본을 마이그레이션 하기 전 마스터가 가지고 있어야 할 최소 복제본 수를 의미
- 복제본이 새로운 마스터로 승격된 이후 해당 노드 장애 발생 시 레디스 클러스터는 각 마스터에 연결된 복제본 노드의 불균형을 파악해 복제본 하나를 새로운 마스터의 복제본으로 이동
- 복제본 선정 기준은 아래 기준을 따름
    1. 가장 많은 수의 복제본이 연결된 마스터의 복제본 중 하나
    2. `FAIL` 상태가 아닌 복제본 노드 중 노드 ID가 가장 작은 복제본
- 모든 마스터가 적어도 1개 이상의 복제본에 의해 복제되는 것을 보장하여 안정성 향상

# 레디스 클러스터 실행하기

## 테스트 서버 정보

- 192.168.0.11 ~ 192.168.0.66
- 마스터 3대, 복제본 3대로 구성

## 클러스터 초기화

### 1) redis.conf 클러스터 설정

```bash
cluster-enabled yes
```

- 레디스를 클러스터 모드로 변경
- 전체 서버에 적용 후 레디스 실행

### 2) 클러스터 생성

```bash
redis-cli -cluster create [host:port, host:port ...] --cluster-replicas 1
```

- `--cluster-replicas` : 마스터마다 몇 개의 복제본을 추가할 것인지
- 초기화 정상 완료 시 `[OK] All 16834 slots covered.` 커맨드 조회 후 생성 종료
- 해시 슬롯은 마스터에만 할당
- 복제본은 마스터와 동일한 데이터를 저장하지만 해시 슬롯을 할당받지는 않음

## 클러스터 상태 확인하기

```bash
$ redis-cli cluster nodes # 랜덤으로 클러스터 내의 노드들을 순서 없이 출력
```

- `id` : 노드 생성 시 자동으로 생성되는 랜덤 스트링 클러스터 ID (변경 불가)
- `id:port@cport` : 노드가 실행되는 IP, Port, 클러스터 버스 Port (Port + 10,000)
- `flags` : 노드 상태
    - `myself` : `redis-cli`를 이용해 접근한 노드
    - `master` : 마스터 노드
    - `slave` : 복제본 노드
    - `fail?` : 노드가 현재 PFAIL  상태 (다른 노드에 장애 발생 여부 확인 시작 상태)
    - `fail` :  노드가 현재 FAIL 상태 (과반수 이상의 노드가 해당 노드에 장애가 발생한 것을 인지)
    - `handshake` : 새로운 노드 인지 후 핸드셰이크 진행중
    - `nofailover` : 복제본 노드가 페일오버를 시도하지 않을 예정
    - `noaddr` : 해당 노드의 주소를 모름
    - `noflags`
- `master` : 복제본 노드일 경우 마스터 노드의 ID, 마스터 노드일 경우 `-`로 표시
- `ping-sent` : 보류 중인 PING이 없다면 0, 있다면 마지막 PING이 보낸 유닉스 타임 표시
- `pong-sent` : 마지막 PONG이 수신된 유닉스 타임 표시
- `config-epoch` : 현재 노드의 구성 에포크
    - 페일오버가 발생할 때마다 에포크 증가, 구성 충돌이 있을 때 에포크가 높은 노드의 구성으로 변경
- `link-state` : 클러스터 버스에 사용되는 링크의 상태 (`connected` / `disconnected`)
- `slot` : 노드가 갖고 있는 해시슬롯의 범위 표시

## `redis-cli`를 이용해 클러스터 접근하기와 리디렉션

- 클라이언트 모드를 지원하는 레디스 클라이언트를 통해 클러스터 접속 가능
    - ex) redis-cli
- `redis-cli`의 경우 `-c` 옵션 미사용 시 마스터 노드의 해시슬롯 범위에 해당하는 데이터만 조작 가능, 사용 시 해당 데이터가 조작 가능한 마스터로 연결 리디렉션
- 대부분의 레디스 클라이언트는 리디렉션한 정보를 캐싱해 맵을 생성, 이후 동일 키에 대해 캐싱한 노드로 바로 커맨드를 보낼 수 있도록 함
- 클러스터에 저장된 맵은 노드가 추가/삭제되거나, 페일오버가 발생하는 등 클러스터의 구조가 변경되면 리프레시

## 페일오버 테스트

### 확인 필요 사항

- 페일오버 정상 동작 여부
- 클러스터 내부 노드 간 통신이 정상적으로 이루어지고 있는지 여부
- 일부 노드 간 네트워크 단절은 없는지 등

### 수동 페일오버

- 페일오버 대상 마스터에 1개 이상의 복제본이 연결되어 있어야 함
- 페일오버 발생시킬 복제본 노드에서 아래 명령어 실행
    
    ```jsx
    cluster failover # 수동 페일오버 실행
    INFO REPLICATION # 복제 연결 상태 확인
    ```
    
    1. 페일오버 시작 전 복제 딜레이 대기
    2. 마스터의 복제 오프셋을 복제본이 따라잡는 작업 진행 
    ❓ 오프셋이 master_repl_offset을 의미하는지, 얘가 데이터 변경될 때마다 증가되는 필드가 맞을지
    3. (2) 완료 후 페일오버 시작
    4. 페일오버 완료 시 클러스터의 정보 변경
    5. (4) 완료 시 클라이언트는 새로운 마스터로 리디렉션
- 페일오버 진행중 기존 마스터에 연결된 클라이언트는 잠시 블락

### 자동 페일오버

- 직접 마스터에 장애 발생시킨 후 페일오버가 정상적인지 확인
- 마스터의 상태가 정상이 아닐 경우 다른 노드에서 이를 인지하는지 확인 가능
- 아래 명령어 통하여 레디스 프로세스 셧다운 및 클러스터 상태 확인
    
    ```bash
    $ redis-cli -h <master-host> -p <master-port> shutdown # 마스터 셧다운
    $ redis-cli cluster nodes # 클러스터 상태 확인
    ```
    
- 복제본은 `cluster-node-timeout` 시간 동안 마스터에서 응답이 오지 않으면 마스터의 상태가 정상적이지 않다고 판단하여 페일오버 트리거 (기본 값 : 15,000ms)

# 레디스 클러스터 운영하기

## 클러스터 리샤딩

- 마스터 노드가 보유한 해시슬롯 중 일부를 다른 마스터로 이동하는 것

### 정식

```bash
$ redis-cli --cluster reshard <ip> <port>

# 1) 이동시킬 슬롯 개수 입력
# 2) 해시슬롯을 받을 노드의 ID 입력
# 3) 해시슬롯을 이동시킬 노드의 ID 입력 : all 입력 시 모든 마스터 노드에서 조금씩 이동
# 4) 리샤딩 계획 조회 및 진행 여부 입력 : YES
```

- 마스터가 아닌 복제본 노드 중 하나를 지정하더라도 리샤딩은 동일하게 동작

```bash
$ redis-cli --cluster check <ip>
```

- 클러스터 정보 상세 확인
- `cluster nodes` 명령어보다 상세 정보 조회

### 간단 버전

- 슬롯 이동이 빈번하거나 자동화를 하고자 할 경우 사용자와의 인터랙션 없이 진행 가능

```bash
redis-cli --cluster reshard <host>:<port> --cluster-from <node-id> --cluster-to <node-id> 
--cluster-slots <number of slots> --cluster-yes
```

- `--cluster-yes` : 모든 프롬프트에 자동으로 `yes`를 입력

```bash
$ redis-cli cluster nodes
```

## 클러스터 확장: 신규 노드 추가

- **추가 대상 마스터/복제본 노드에는 데이터가 저장되지 않은 상태여야 함**
    - 비어 있지 않은 경우 `[ERR] Node <ip>:<port> is not empty.` 오류 발생
- 추가하고자 하는 노드도 설정 파일 내 `cluster-enabled yes`가 추가되어 클러스터 노드로 실행된 상태여야 함

### 마스터로 추가

```bash
redis-cli --cluster add-node <new node ip:port> <exist node ip:port>
```

- 새로운 노드 추가 전 기존 노드의 상태를 확인한 뒤 새로운 노드 추가

```bash
$ redis-cli cluster nodes
```

- 정상 구성 여부 확인

⇒ 데이터를 저장하려면 리샤딩 기능을 사용해 해시슬롯 할당 필요

### 복제본으로 추가

```bash
redis-cli --cluster add-node <new node ip:port> <exist node ip:port>
--cluster-slave [--cluster-master-id <기존 마스터 ID>]
```

- 복제본의 마스터가 될 노드를 지정해주면 신규로 추가하는 노드는 지정한 마스터의 복제본이 됨
- `--cluster-master-id` 옵션 없이 커맨드 실행 시 임의의 마스터의 복제본으로 연결
    - 클러스터가 대칭적인 구조가 아닌 경우 복제본이 적게 연결되어 있는 마스터에 연결

## 노드 제거

```bash
redis-cli --cluster del-node <exist node ip:port> <delete target ID>
```

- 제거 대상 노드가 마스터인지 복제본인지에 상관 없이 모든 노드를 같은 방식으로 삭제 가능
- 마스터 노드 제거 시 제거 전 노드에 저장된 데이터가 없어야 함
    
    (= 할당된 해시슬롯이 존재하지 않는 상태여야 함)
    
- **따라서 해시슬롯을 모두 다른 노드로 리샤딩하는 작업 선행 필요**

### CLUSTER FORGET

- 클러스터 노드 제거 전 클러스터 내 다른 노드들에게도 해당 노드를 지우라는 커맨드 발송
- 그렇지 않을 경우 다른 노드는 여전히 삭제된 노드의 ID와 주소를 기억하고 있게 됨

```bash
CLUSTER FORGET <node-id>
```

- 커맨드 수신한 노드는 노드 테이블에서 대상 노드 삭제 후 60초 동안 해당 노드 ID를 가지고 있는 노드와 신규로 연결되지 않도록 설정
- 통신 차단하지 않으면 다른 노드에 의해 제거된 노드를 가십 프로토콜을 통하여 추가될 가능성 존재

### CLUSTER RESET

```bash
CLUSTER RESET [SOFT/HARD] # 기본 값 : SOFT
```

- 클러스터에서 제거될 노드가 수행
- 사용자가 특정 클러스터 노드를 다른 역할로 재사용하고자 하는 경우에도 노드에 직접 수행

**동작 과정**

1. 클러스터 구성에서 복제본이었다면 마스터로 전환 후 노드가 가지고 있던 모든 데이터 삭제
    
    마스터이고 저장된 키가 있을 경우 리셋 작업 중단
    
2. 노드가 해시슬롯을 가지고 있었다면 모든 슬롯 해제,
    
    만약 페일오버 진행 중인 경우 페일오버에 대한 진행 상태도 초기화
    
3. 클러스터 구성 내 다른 노드 데이터 초기화
    
    클러스터 버스를 통해 연결됐던 노드 인식 불가
    
4. `currentEpoch`, `configEpoch`, `lastVoteEpoch` 값이 0으로 초기화
5. 노드의 ID가 새로운 임의 ID로 변경

⇒ HARD는 1~5번 수행

⇒ SOFT는 1~3번 수행

## 클러스터로의 데이터 마이그레이션

- `redis-cli`로 싱글 혹은 센티널로 사용하고 있던 노드를 클러스터로 마이그레이션 가능

### 마이그레이션 전제 조건

- 데이터가 저장될 클러스터 노드는 해시슬롯 16,834개가 모두 정상적으로 할당된 상태
- 클러스터 내의 마스터 노드에 모두 접근이 가능한 상태로 준비
- 데이터의 소스 노드 또한 접근이 가능한 온라인 상태

### DATA IMPORT

```bash
redis-cli --cluster import 192.168.0.11:6379 --cluster-from 192.168.0.88:6379 --cluster--copy
```

1. 데이터를 전달 받을 클러스터 노드에서 소스 레디스 노드로 데이터 import 요청
2. 데이터를 받아 올 클러스터가 정상 상태인지 확인
3. 데이터 마이그레이션 시작

## 복제본을 이용한 읽기 성능 향상

- 키 요청 시 키를 갖고 있는 마스터 노드로 연결을 리디렉션
- 해당 마스터에 연결된 복제본 노드는 같은 데이터를 갖고 있기 때문에 키를 읽을 수 있지만,
    
    이 경우에도 우선 마스터로 연결을 변경
    
- 하지만 성능을 위하여 Write는 마스터, Read는 복제본에 진행하도록 커넥션 분배 가능
    
    ```bash
    $ redis-cli -h <ip> -c
    <ip>:<port>> readonly # 복제본 노드에 있는 데이터 직접 조회 가능
    OK
    ```
    

# 레디스 클러스터 동작 방법

## 하트비트 패킷

- 클러스터 노드들은 지속적으로 서로의 상태를 확인하기 위해 **PING, PONG 패킷**을 주고 받음
- 클러스터가 주고 받는 유형의 패킷에 **가십 섹션**이 추가된 형태
- 하트비트 패킷을 받은 클러스터 노드는 다른 노드에 대한 정보를 알 수 있고,
    
    이를 통해 다른 노드를 알게 되거나 장애도 감지할 수 있게 됨
    
- 클러스터 생성 시 모든 노드의 현재 에포크 값은 `0`
- 다른 노드들과 통신 시 에포크 값을 확인 시 `수신 받은 패킷의 에포크 값` > `로컬 노드의 값`인 경우 현재 에포크 값을 송신한 노드의 에포크 값으로 업데이트
    - 결국 모든 노드는 클러스터에서 가장 큰 구성 에포크 값으로 통일
    - **이 값은 클러스터 상태 변경 시, 페일오버 발생 시 동의를 구하기 위해 사용**

### 일반 클러스터 패킷 헤더

아래 정보 포함하고 있음

- `노드 ID`
- `현재 에포크/구성 에포크` : 분산 환경에서 일관성을 유지하기 위한 정보
- `노드 플래그` : 노드가 마스터인지 혹은 복제본인지 등의 노드 정보
- `비트맵` : 마스터가 제공하는 해시슬롯의 비트맵 정보, 복제본인 경우 마스터의 정보
- `TCP 포트` : 발신 노드의 TCP 포트
- `클러스터 포트` : 발신 노드의 노드 간 커뮤니케이션을 위한 포트
- `클러스터 상태` : 발신 노드 관점에서 봤을 때의 클러스터 상태 (`down`/`ok`)
- `마스터 노드 ID` : 복제본 노드인 경우 마스터의 노드 ID

### 하트비트 패킷 헤더

위 내용에 아래 내용 추가

- `가십 섹션` : 발신하는 노드가 알고 있는 클러스터 내의 랜덤한 몇 개의 다른 노드 정보
    - 노드별 `노드 ID`, `IP/포트 쌍`, `노드 플래그` 정보 포함

## 해시슬롯 구성이 전파되는 방법

- 커맨드에서 사용한 키의 해시슬롯이 어디에 있는지 파악해 정확한 해시슬롯을 찾는 것은 중요
- 클러스터에서 해시슬롯 구성은 두 가지 방법으로 전파
- 클러스터 시작 시 모든 노드의 해시슬롯은 `NULL`로 초기화
- **해시슬롯 구성의 변경은 페일오버와 리샤딩 중에만 발생** ⇒ 모두 에포크가 증가하는 작업
    - 작업 이후 클러스터 전체에 전파 진행
- 모든 클러스터 노드는 가장 큰 구성 에포크 값을 가진 노드에 동의하여 노드 값 업데이트 가능

### 하트비트 패킷

- 마스터 노드가 PING, PONG 패킷을 보낼 때 항상 자기가 갖고 있는 해시슬롯을 패킷 데이터에 추가

### 업데이트 메시지

- 하트비트 패킷에는 발신하는 노드의 구성 에포크 값이 포함되어 있음
- 패킷을 보낸 노드의 에포크 값이 오래됐다면 해당 패킷을 받은 노드는 신규 에포크의 구성 정보를 포함한 업데이트 메시지를 노드에 보냄

⇒ 하트비트 패킷을 보낸 노드의 해시슬롯 구성을 업데이트

## 노드 핸드셰이크

```bash
CLUSTER MEET # 방향성이 존재하지 않아 A->B 송신 이후 B->A 송신 불필요
```

1. 한 노드가 클러스터에 합류하기 위해 위 커맨드를 다른 노드에 보냄
2. 해당 커맨드를 수신한 노드는 자신이 알고 있는 다른 노드들에게 전파
3. 이 정보를 수신한 노드가 신규 합류한 노드를 모르는 상태라면 해당 노드와 `CLUSTER MEET` 명령어를 통해 신규 연결을 맺게 됨
4. 해당 노드를 이미 알고 있다면 `CLUSTER MEET` 커맨드 무시

⇒ 이와 같은 방식으로 클러스터 내부의 모든 노드들은 Full-Mesh 연결

## 라이브 상태의 클러스터 재구성

- 운영 중 신규 마스터 추가 및 제거 가능
    - `추가` : 빈 노드를 클러스터에 추가한 뒤, 일부 해시슬롯을 기존 마스터에서 신규 노드로 옮김
    - `제거` : 제거 대상 노드가 갖고 있던 해시슬롯을 다른 노드로 보냄
- **아래 커맨드 실행 중 노드 A가 옮기고 있는 해시슬롯에 대한 쿼리를 받은 경우**
    
    **기존 존재 쿼리를 조회한다면 A에서, 신규 키를 생성하는 쿼리라면 B 노드로 리디렉션**
    
- 데이터 마이그레이션 시 두 개 인스턴스 모두 락이 발생하며, 경쟁 상황은 발생하지 않음
- 마이그레이션 시 대상 인스턴스에 연결해 키를 전송하고 완료되면 기존 데이터 셋에서 키를 삭제

### 수행 과정

A에서 B로 해시슬롯을 옮기는 경우 아래와 같이 수행

```bash
# A에게
CLUSTER SETSLOT {slot} MIGRATING B

# B에게
CLUSTER SETSLOT {slot} IMPORTING A

# 슬롯이 보유한 키 반환 및 MIGRATE 커맨드 전송
CLUSTER GETKEYINSLOT {slot} {count}

# 데이터 마이그레이션
MIGRATE target-host target-port key target-database id timeout

# 데이터 마이그레이션 완료 시 두 노드에 전송되는 커맨드
CLUSTER SETSLOT <slot> NODE <node-id> # 다른 모든 노드로 전파됨
```

## 리디렉션

- 트래픽이 많은 서비스는 다른 노드에 커넥션을 다시 한 번 맺는 과정이 많아졌을 때 성능 저하

### MOVED 리디렉션

- 요청하는 해시슬롯이 다른 노드에 있으니 이 키에 대한 요청은 다른 노드로 보내라고 하는 것
- 원하는 해시슬롯이 없을 경우 해시슬롯맵 확인 후 `MOVED` 에러로 클라이언트에 응답
- 응답 시 해당 해시슬롯을 갖고 있는 마스터 노드의 정보 반환

⇒ 클라이언트는 이를 이용해 다시 질의, SPOF 방지

### ASK 리디렉션

- 현재 요청한 이 쿼리는 다른 노드에서 수행하지만 다음 노드는 다시 현재 노드로 요청
- 해시슬롯이 이동되는 과정에서만 발생
- 아래와 같이 동작
    1. 리디렉션 오류가 반환한 노드 정보로 쿼리 재전송,
    이후에 같은 키에 대한 쿼리가 들어오면 기존에 전송한 노드에 다시 보냄
    2. 리디렉션을 받은 값으로 클라이언트의 해시슬롯맵을 업데이트하지 않음

## 장애 감지와 페일오버

- 대부분의 노드가 특정 노드에 접근할 수 없다는 것을 인지하면 해당 노드의 상태 변경
- 장애 감지에 사용되는 플래그는 아래와 같음

### PFAIL 플래그 (Possible failure)

- 일부 노드에서는 해당 노드에 접근할 수 없지만, 아직 확실하진 않은 실패임을 의미
- 마스터/복제본 상관 없이 특정 노드에 `NODE_TIMEOUT` 시간 이상 도달할 수 없는 경우 표시
    - 해당 노드에 PING 패킷을 보냈지만 PONG 패킷을 받지 못한 상태
- 노드 간 왕복 시간보다 `NODE_TIMEOUT`은 더 커야 함
- PING을 보낸 뒤 `NODE_TIMEOUT` 의 절반 시간 동안 PONG을 받지 못했을 때
    
    해당 노드에게 PING을 다시 보내 안정성 향상
    

### FAIL 플래그

- 대다수의 노드에서 해당 노드에 장애가 발생했음을 동의한 상태
- 특정 노드가 PFAIL로 플래깅 되고 이후 클러스터 내의 다른 노드가 보낸 하트비트 패킷에서 해당 노드의 상태를 들음
- 이때 일정 시간 내에 다른 노드에서 해당 노드에 대한 PFAIL, FAIL 알림을 받으면 FAIL로 플래깅

❓ 두 번째 문장의 다른 노드와 세 번째 문장의 다른 노드는 서로 다른 노드일지 (325pg)

## 복제본 선출

- 아래 조건 모두 만족 시 복제본은 마스터로 선출되기 위해 자신의 현재 에포크 값을 1 증가,
    
    마스터 인스턴스에게 투표 요청
    

### 복제본의 페일오버 시도 조건

1. 마스터가 FAIL 상태
2. 마스터가 1개 이상의 해시슬롯을 갖고 있음
3. 마스터와의 복제가 끊어진 지 오래 (파라미터로 조절 가능)

### 투표 진행 과정

1. 모든 마스터 노드에 `FAILOVER_AUTH_REQUEST` 패킷을 보내 투표 요청
(아래 딜레이 후 투표 시작)
    
    ```bash
    DELAY = 500ms + 랜덤 지연 시간 (0~500ms) + SLAVE_RANK * 1000ms
    
    # 랜덤 지연 시간 : 여러 복제본에서 동시에 투표를 시작하는 것을 방지
    # SLAVE_RANK : 마스터에서 처리한 복제 데이터의 양과 관련된 복제본의 우선순위
    # (FAIL 상태 이후 복제본끼리 메시지 교환, 가장 최근 오프셋을 가진 복제본이 0순위)
    ```
    
2. 요청을 받은 마스터는 `FAILOVER_AUTH_ACK` 패킷으로 긍정 응답을 보내 투표에 동의함
3. 이때 동시에 다른 복제본을 승격시키는 것을 방지하기 위해 `NODE_TIMEOUT * 2` 시간 동안은 
    
    같은 마스터로 승격되고자 하는 다른 복제본에게는 투표할 수 없음
    
4. 응답을 받은 복제본은 현재 에포크 값보다 작은 에포크로 온 `FAILOVER_AUTH_ACK` 무시,
    
    이전 버전의 투표에 대한 응답은 거를 수 있음
    
5. 다수의 마스터로부터 ACK를 받은 복제본이 마스터 후보로 선출됨,
    
    `NODE_TIMEOUT * 2` 시간 동안 과반수 이상의 마스터에서 ACK가 오지 않으면 페일오버 중단
    
    `NODE_TIMEOUT * 4` 만큼의 지연 후 다시 새로운 투표 시도 가능
    

# 추가로 알게 된 점

## 1) 가십 프로토콜

1. X개의 노드들을 Random하게 고른다
2. 고른 노드들에게 데이터를 전송하고 Gossip Muticast에 참여하게 한다.

[Gossip 프로토콜이란?](https://medium.com/@heonjang.lee96/gossip-프로토콜이란-906500c3de4b)
